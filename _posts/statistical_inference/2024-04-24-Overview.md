---
layout: single
category: 통계적 추론
title: "Overview"
use_math: true
---
## Convergence in Probability
### Definition
$lim_{n \to \infty} P(|X_n - X|\geq \epsilon) =0$

### Linearity of Convergence in probability
- IF $X_n \xrightarrow{p} X, Y_n \xrightarrow{p} Y$ 

    then, $X_n +Y_n \xrightarrow{p} X+Y$
- $X_n \xrightarrow{p} X, a \neq 0$


    $aX_n \xrightarrow{p}aX$
### Continuous Mapping Theorem
$X_n \xrightarrow{p} X$

Consistency를 보이는 방법
1.	WLLN
    
    iid한 r.v.들의 평균은 r.v.의 기대값으로 확률적으로 수렴한다.
2.	WLLN + CMT
3.	def → Chev’s inequality
    
    $lim_{n \to \infty }P(|\bar X_n - \mu| \geq \epsilon) \leq lim_{n \to \infty }\frac{[Var(\bar X_n)]}{\epsilon^2}$
4.	def → 분포 =0
    

## Convergence in Distribution
Find the limiting distribution of $X_n$
- Slutsky’s thm.
    
    $X_n \xrightarrow{d} X, Y_n \xrightarrow{p} c$,

    $X_n  Y_n \xrightarrow{d} cX$


- Central Limit Thm(CLT)
  
  $\sqrt{n}(\bar X_n - \mu) \xrightarrow{d}N(0,\sigma^2)$

- $\Delta$-method
  
    if $\sqrt{n}(\bar X_n - \mu) \xrightarrow{d}N(0,\sigma^2)$,

    $\sqrt{n}(g(\bar X_n) - g(\mu)) \xrightarrow{d}N(0,[g'(\mu)]^2\sigma^2)$

## Maximum Likelihood Estimator(MLE)
### How to find MLE
1.	$l'(\theta) = 0$
2.	$l''(\theta) <0$ (concave)
3. concave 하지 않을 때는 $l'(\theta) =0$ 기준으로 증/감을 살펴보자
4. Inregular case

    $l'(\theta) = 0$ is not depend on $\theta$

### Invariance Property
$\eta = g(\theta)$
If $\hat\theta$ is the MLE of $\theta$, 

then the MLE of $\eta$ is $\hat\eta = \hat{g(\theta)}=g(\hat\theta)$

### Consistency
(R0) $\theta_1 \neq \theta_2 \to f(x|\theta_1) \neq f(x|\theta_2)$

(R1) the supprot of $f(x|\theta)$ does not depend on $\theta$

(R2) the true parameter $\theta_0$ is an interior point in $\Omega$
조건 하에 

the MLE of $\theta$ is consistent

$\hat\theta \xrightarrow{p} \theta$


## Efficient Estimator
### How to show Efficient Estimator
1.	Unbiased Estimator
2.	$var_\theta(\hat\theta) = \frac{1}{nI_1(\theta)}$

### Score Function
$\frac{d}{d\theta}log(f(x;\theta))$
### Fisher Information
$I(\theta)\\ = E_\theta[l'(\theta)^2] \\= -E[l''(\theta)] \\=Var_\theta[l(\theta)]$
### Cramer-Rao lower bound (CRLB)
1. unbiased estimator(UE)
2. $Var_\theta(\hat\theta) \geq \frac{1}{nI_1(\theta)}$

### achieve CRLB
$Var_\theta(\hat\theta) = \frac{1}{nI_1(\theta)}$

### Efficiency
$\frac{1}{nI_1(\theta)Var_\theta(\hat\theta)} = \frac{CRLB}{var_\theta(\hat\theta)}$

### Asymptotic Properties
1. Asymptotic normality of MLE
   
    $\sqrt{n}(\hat\theta -\theta_0) \xrightarrow{d} N(0, \frac{1}{I_1(\theta_0)})$


2. Asymptotic CI of $\theta$
   
   $[\hat\theta - Z_{\alpha/2}\frac{1}{\sqrt{nI_1(\theta)}}, \hat\theta + Z_{\alpha/2}\frac{1}{\sqrt{nI_1(\theta)}}]$

    cf) 모평균의 신뢰구간

    $P(|\frac{\sqrt n}{\sigma}(\bar X -\mu)| \leq z_{\alpha/2}) = 1-\alpha$

    $[\bar X - z_{\alpha/2} \frac{\sigma}{\sqrt n}, \bar X + z_{\alpha/2}\frac{\sigma}{\sqrt n}]$

3. Asymptotic relative efficiency(ARE)

	- $\hat\theta_{1n}$ and $\hat\theta_{2n}$ is asymptotically distributied to normal,

         $\sqrt n (\hat\theta_{1n} - \theta) \xrightarrow{d} N(0, \sigma_1^2)$

        $\sqrt n (\hat\theta_{2n} - \theta) \xrightarrow{d} N(0, \sigma_2^2)$

    - show $\hat\theta_{1n}$ is efficient
$\frac{1/I_1(\theta_0)}{\sigma_1^2} =1$
    - calculate ARE
  
        $e(\hat\theta_{1n}, \hat\theta_{2n}) = \sigma_2^2/{\sigma_1^2}$

4. Asymptotic distribution of a function of MLE

    $\sqrt n [g(\hat\theta) -g(\theta_0)] \xrightarrow{d} N(0, \frac{[g'(\theta_0)]^2}{I_1(\theta_0)}$


## Sufficient Statistic
### Factorization theorem(FT)
### Rao- Blackwell
$\hat \theta_1 : unbiased$

$T(\underline X) : SS$

$\hat\theta_2 = E[\hat\theta_1|T(\underline{X})]$ is unbiased and $V(\hat\theta_2) \leq V(\hat\theta_1)$

### Minimal Sufficient statistic(MSS)

## Complete Statistic
### Complete Statistic(CS)
$E_\theta[g(T)]=0,\forall \theta$ implies $P_\theta(g(T) = 0) =1, \forall\theta$

성립하면, $T= T(X)$ 가 CS이다.

### Complete Sufficient Statistic(CSS)
$T =CS+SS$

